{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b09256-8097-4588-938f-37a2f16507c4",
   "metadata": {},
   "source": [
    "# Workbench for ResumeAssistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79634a30-eea3-403d-935a-a66ce9bd5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "# ImageWorker takes in the path to jpg resume image and returns the contents of the resume in a json format. \n",
    "from resumeassistant.operator.worker import ImageWorker, TextWorker\n",
    "from resumeassistant.data.candidate_record import Record, QA_Knowledge\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad03abd-9b24-4e84-924b-07b7bd8f27ff",
   "metadata": {},
   "source": [
    "# PDF to jpg image converter function\n",
    "This function takes the input path for pdf-resume and output path for resume image. The output images are stored in 'jpg' format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffade2-11d4-42ee-bd17-d24ce4ec87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(pdf_path, img_path):\n",
    "      # Method for converting pdf resumes to jpg images. \n",
    "      images = convert_from_path(pdf_path)\n",
    "      # print(type(images))\n",
    "      for i in range(len(images)):\n",
    "        \n",
    "            # Save pages as images in the pdf\n",
    "          images[i].save(img_path + str(i) +'.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a3b50-9801-47d7-89c1-108bc0e3c9a5",
   "metadata": {},
   "source": [
    "This is the code to extract OpenAI key stored in `gpt_key.json` file. \\\n",
    "Format: \\\n",
    "    ```{ \n",
    "\t\"api_key\": \\<open_ai_key\\>\n",
    "    }```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffad11-5857-4851-bad4-e63cb22a1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_key.json', 'r') as file:\n",
    "      data = json.load(file)\n",
    "      api_key = data[\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459786a-75de-4155-b004-ac40c32c1b23",
   "metadata": {},
   "source": [
    "## Resume Parsing\n",
    "This is the code for converting the PDF resume to an image and parsing it using \"GPT-4o\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2858039-6d9f-4c40-b436-ec9e47dc1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "get_img('Resume_PhD.pdf', './Harish_Resume')\n",
    "\n",
    "sys_prompt = \"You are a resume parser. Given the image of the resume, parse every section and provide the output in a JSON format.\"\n",
    "user_prompt=\"Can you parse all sections of this resume?\"\n",
    "\n",
    "image_worker = ImageWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=sys_prompt, user_prompt=user_prompt)\n",
    "parsed_resume = image_worker.get_output('Harish_Resume0.jpg')\n",
    "print(parsed_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7061118-f685-4836-8cd0-646c24949a76",
   "metadata": {},
   "source": [
    "## Add CV and additional information\n",
    "The current_cv instance keeps a record of the most recent updated Cover Letter and additional information on work experience, projects, achievements, and certifications. \n",
    "\n",
    "### Input arguments:\n",
    "`resume`=Parsed resume (Dict). \\\n",
    "`cv` = Cover letter text. \\\n",
    "`add_skills` = Additional skills not mentioned in the resume (Dict). \\\n",
    "`add_work_experience` = Additional work experience not mentioned in the resume (Dict). \\\n",
    "`add_education` = Additional education not mentioned in the resume (Dict). \\\n",
    "`add_projects` = Additional Projects not mentioned in the resume (Dict). \\\n",
    "`add_achievements` = Additional achievements not mentioned in the resume (Dict). \\\n",
    "`add_certifications` = Additional certifications not mentioned in the resume (Dict). \n",
    "\n",
    "#### additional_information format:\n",
    "```{``` \\\n",
    "```\"information\": text,``` \\\n",
    "```\"organization\": text,``` \\\n",
    "```\"date\": \"dd/mm/yyyy - dd/mm/yyyy\" (or) \"dd/mm/yyyy\"``` \\\n",
    "```}```\n",
    "\n",
    "The job_listing instance keeps a record of the requirements and description of the job posting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6c5a8-649f-4d08-b625-1a680a9ec18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed_resume.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf707847-93a0-406f-ba52-764d1e63b86c",
   "metadata": {},
   "source": [
    "## Resume Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1962296-a716-41bb-9b5a-480f16577eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_resume(candidate_info, job_description):\n",
    "    ro_system_prompt = 'You are a resume optimizer. \\\n",
    "    Given the candidate information(#candidate_info) and the job description(#job_description), \\\n",
    "    rewrite the current resume to highlight the relevant skills, experience, and quantifiable achievements that match the job description. \\\n",
    "    Provide the output in a JSON format.'\n",
    "    \n",
    "    ro_user_prompt = f'#candidate_info: {candidate_info} \\\n",
    "                    \\n#job_description: {job_description}'\n",
    "    \n",
    "    ro_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=ro_system_prompt, user_prompt=ro_user_prompt, json_format=True)\n",
    "    new_resume = ro_text_worker.get_output()\n",
    "    return new_resume\n",
    "# print(new_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a0b0d-b45b-4490-beb0-6627f5947dfc",
   "metadata": {},
   "source": [
    "## Resume Screening\n",
    "In this section, the generated resume is screened based on how informative it is w.r.t the job posting. \n",
    "The resume screener gathers the keywords from the job description where the new resume fails to address, and a question requesting the missing information to address the unfulfilled requirements. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf2e0e-418a-4fce-952c-dfba798e19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_resume_CL(resume, cover_leter, job_description):\n",
    "    ra_system_prompt = 'You are a resume and cover letter screener.\\\n",
    "                        given the current resume(#current_resume), cover letter(#current_cover_letter) and the \\\n",
    "                        job description(#job_description), \\\n",
    "                        provide keywords from the job description where the resume and the cover letter fail to address the requirements. \\\n",
    "                        Provide the keywords with a question describing how the resume and the cover letter fail to meet this requirement. \\\n",
    "                        Present the output in the following JSON output format: \\\n",
    "                        \\n\\t{\\\"keywords\\\": [{\"keyword\": system keyword, \"question\": system keyword question}]}'\n",
    "    # ra_user_prompt = f'#current_resume: {record.resume} \\\n",
    "                        #job_description: {job_description}'\n",
    "    \n",
    "    ra_user_prompt = f'#current_resume: {resume} \\\n",
    "                        #job_description: {job_description} \\\n",
    "                        #current_cover_letter: {cover_leter}' \n",
    "    \n",
    "    ra_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=ra_system_prompt, user_prompt=ra_user_prompt, json_format=True)\n",
    "    system_insights = ra_text_worker.get_output()\n",
    "    return system_insights\n",
    "# print(system_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357537e-0068-4c44-841c-e0436280de95",
   "metadata": {},
   "source": [
    "## Cover Letter Generation\n",
    "This is the code for generating the cover letter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58ec11-f753-4edd-a5be-103b6de966bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CL_generator(candidate_info, job_description):\n",
    "\n",
    "    cl_system_prompt = \"You are a cover letter generator, given the candidate information(#candidate_info) and job description(#job_description). \\\n",
    "                        Generate a cover letter relevant to the job description highlighting the candidate's skills and achievements\"\n",
    "    \n",
    "    cl_user_prompt = f'#candidate_info: {candidate_info} \\\n",
    "                        #job_description: {job_description}'\n",
    "    \n",
    "    \n",
    "    cl_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=cl_system_prompt, user_prompt=cl_user_prompt)\n",
    "    new_cl = cl_text_worker.get_output()\n",
    "    return new_cl\n",
    "# print(new_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305747b4-3a20-425e-885f-8066cf8aacb9",
   "metadata": {},
   "source": [
    "## Create the Candidate-Record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1eb67d-fd26-48b8-9567-a0bb73cacd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cl = \"Hello Hiring Team, \\nI am pursuing my Ph.D. in the Computer Engineering department at Stevens Institute of Technology; \\\n",
    "            my research is focused on Natural Language Processing. \\\n",
    "            I work on applications related to the areas of Misinformation Research and Investigative Journalism using Evidence Extraction, \\\n",
    "            Fact Verification and Key-Phrase analysis; I research and work with Generative Models, Deep Learning models, Attention Networks, \\\n",
    "            and Large Language Models for Extraction and Verification Tasks. \\\n",
    "            My Dissertation Project is based on Fact-Verification and Evidence-Extraction using an Explainable Prompt-Engineering Model \\\n",
    "            I proposed. \\nEven though I chose the use cases of NLP as the focus of my research, \\\n",
    "            my work is more comprehensive than NLP-based models; \\\n",
    "            I have also created a low-cost Derivative-Free Optimization Method for parameter optimization in ML; \\\n",
    "            I am working on obtaining a Provisional Patent for this research. \\\n",
    "            I am immensely passionate about learning and analyzing the underlying Mathematical Concepts of Machine Learning Models; \\\n",
    "            I like educating myself on all the specifics of any problem statement, following the motivation of the research, \\\n",
    "            chronological evolution of the Problem-Solution framework, and feature analysis from historical to the SOTA models. \\\n",
    "            \\nI am currently seeking a job opportunity to hone my skills and work with a proficient team for an inspirational \\\n",
    "            cause where AI can be efficacious. \\nRegards, \\nHarish Sista, Ph.D. candidate, \\nComputer Engineering Department, \\\n",
    "            \\nStevens Institute of Technology.\"\n",
    "\n",
    "record = Record(resume=parsed_resume, cl=old_cl)\n",
    "with open('job_description.txt', 'r') as f:\n",
    "    job_description = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c7fb0-cb6e-40fd-ba7b-f566f118e489",
   "metadata": {},
   "source": [
    "## Analyze missing information using Resume screener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85585c-1a2c-4280-91c5-3e36f6936c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_questions = screen_resume_CL(record.resume, record.cl, job_description)\n",
    "print(key_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5631e2f6-3d1b-445d-915d-1113e2d9fd1b",
   "metadata": {},
   "source": [
    "## Add additional information generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e4096-62f2-45fd-ab2e-4b417975abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_knowledge = QA_Knowledge(0, key_questions)\n",
    "\n",
    "#Add custom keywords and questions\n",
    "key_q2 = {'keywords': \n",
    "          [{'keyword': 'data preprocessing and feature engineering', \n",
    "            'question': 'Can you explain how your resume reflects proficiency in data preprocessing and feature engineering techniques?, \\\n",
    "            particularly scikit-learn?'}, \n",
    "           {'keyword': 'collaborate with cross-functional teams to integrate AI solutions', \n",
    "            'question': \"Can you provide examples from your resume that demonstrate your experience \\\n",
    "                  collaborating with cross-functional teams to integrate AI solutions?\"} \n",
    "           ]}\n",
    "add_knowledge.add_key_questions(2, key_q2)\n",
    "\n",
    "#Add candidate answers as key-knowledge. \n",
    "key_knowledge = {'5+ years of experience in working with AI/LLMs': \n",
    "                 {'question': 'How does the resume demonstrate at least 5 years of experience specifically working with \\\n",
    "                 AI and large language models (LLMs) in a direct capacity?',\n",
    "                    'answer': 'As a part of my six years of PhD research in NLP, I have worked on various projects based on knowledge extraction from scholarly data and evidence extraction and fact verification of social-media data using web-scraped real-world data. I used LLMs for building all these projects.'\n",
    "                 }, \n",
    "                 'data preprocessing and feature engineering':{ \n",
    "                'question': 'Can you explain how your resume reflects proficiency in data preprocessing and feature engineering techniques?',\n",
    "                 'answer': 'In my PhD program, I have worked on different varieties of datasets like medical data(CORD-19, PubMed), \\\n",
    "                 social media data(CoVerifi), scholarly data(FEVER-dataset), and real-world data(AVeriTec). \\\n",
    "                 All these datasets use different feature spaces. To process these datasets \\\n",
    "                 I have used various feature engineering techniques like Prompt Engineering, Entity Extraction, key-word extraction, \\\n",
    "                 parts-of-speech tagging and text denoising using Python\\'s RegEx library.'}, \n",
    "                 'Experience with big data tools and technologies (e.g., Hadoop, Spark)': { \n",
    "                  'question': 'How does the resume and cover letter demonstrate experience with big data tools and \\\n",
    "                  technologies such as Hadoop or Spark?',\n",
    "                 'answer': None}, \n",
    "                 'strong understanding of machine learning algorithms and techniques':{\n",
    "                  'question': 'How does your resume showcase a strong understanding of various machine learning \\\n",
    "                  algorithms and their techniques?',\n",
    "                 'answer': None}, \n",
    "                 'collaborate with cross-functional teams to integrate AI solutions': { \n",
    "                  'question': 'Can you provide examples from your resume that demonstrate your experience \\\n",
    "                  collaborating with cross-functional teams to integrate AI solutions?',\n",
    "                 'answer': 'In my previous job at \\'Fresh Digital Group,\\' I have collaborated with various teams like content writers \\\n",
    "                 and UI designers to brainstorm on building structure for chat applications and designing UI for mobile applications.'}}\n",
    "print(type(key_knowledge))\n",
    "add_knowledge.add_knowledge(key_knowledge)\n",
    "print(add_knowledge.get_knowledge())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584752fd-6aca-4b57-8c67-512d2e8370b1",
   "metadata": {},
   "source": [
    "## Add additional information to the candidate record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b49e94-c892-4cfc-8ff0-6a4345ffbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "record.add_knowledge=add_knowledge.get_knowledge()\n",
    "\n",
    "#Get candidate's updated record\n",
    "print(record.get_record())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de3acc9-9161-4aa5-a60e-dcffe902ef35",
   "metadata": {},
   "source": [
    "## Generate new cover letter using candidate record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33747cb-3687-4ff4-8e73-af90b9121231",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('job_description.txt', 'r') as f:\n",
    "    job_description = f.read()\n",
    "new_cl = CL_generator(record.get_record(), job_description)\n",
    "print(new_cl)\n",
    "\n",
    "# We can give the user the capability of the number of words in a cover letter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120faf6c-5ebf-4ba9-a381-e21bc1419f14",
   "metadata": {},
   "source": [
    "## Generate new Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44e48b-f054-4830-923f-05aabc36db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_resume = generate_resume(record.get_record(), job_description)\n",
    "print(new_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7462f-8abc-4ca7-ac46-21aa4781da7a",
   "metadata": {},
   "source": [
    "### Re-run Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce8519-2441-4eda-9e96-61ae3d17062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_questions = screen_resume_CL(record.resume, new_cl, job_description)\n",
    "print(key_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49358544-a0da-4666-ba6f-941cce8d245a",
   "metadata": {},
   "source": [
    "### Add more knowledge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edb3ea-46de-4255-80c5-a8523a56c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_knowledge = {'large-scale LLMs in the 10s to 100s of billions of parameters': \n",
    "                 {'question': 'How does the candidate\\'s experience with LLMs apply to large-scale models with billions \\\n",
    "                 of parameters, and is there any specific mention or evidence of working at this scale?',\n",
    "                    'answer': 'In my Fact Verification Research, I have worked on GPT-4o(which has 1.7 Trillion parameters), \\\n",
    "                    LLAMA-3 8B, and MISTRAL 7B are close to 10B parameters. I have implemented these models on \\\n",
    "                    AWS EC2 and serverless environments like FireworksAI and LightningAI.' }, \n",
    "                 'specialized expertise in topics like fine-tuning, RLHF, LLM tool-use':{ \n",
    "                'question': 'Does the candidate demonstrate specialized expertise in RLHF \\\n",
    "                (Reinforcement Learning from Human Feedback) or other LLM tool-use techniques as outlined in the job description?',\n",
    "                 'answer': 'In my Fact Verification research, I have worked on various prompt engineering techniques to reduce \\\n",
    "                 hallucination in LLMs. I also built a resume application that takes feedback from the candidate to optimize their profile.'}, \n",
    "                 'democratizing access to modern AI technology': { \n",
    "                  'question': 'How does the candidate intend to contribute \\\n",
    "                     to the democratization of AI technology, and what initiatives or projects have they been involved in that align with this goal?',\n",
    "                 'answer': 'I am currently collaborating with a team of developers to convert my resume application to a web application and make it \\\n",
    "                 open-source for everyone on Git Hub.'}, \n",
    "                 }\n",
    "print(type(key_knowledge))\n",
    "add_knowledge.add_knowledge(key_knowledge)\n",
    "print(add_knowledge.get_knowledge())\n",
    "record.add_knowledge.update(add_knowledge.get_knowledge())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
