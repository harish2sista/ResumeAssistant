{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b09256-8097-4588-938f-37a2f16507c4",
   "metadata": {},
   "source": [
    "# Workbench for ResumeAssistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79634a30-eea3-403d-935a-a66ce9bd5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "# ImageWorker takes in the path to jpg resume image and returns the contents of the resume in a json format. \n",
    "from resumeassistant.operator.worker import ImageWorker, TextWorker\n",
    "from resumeassistant.data.candidate_record import Record\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad03abd-9b24-4e84-924b-07b7bd8f27ff",
   "metadata": {},
   "source": [
    "# PDF to jpg image converter function\n",
    "This function takes the input path for pdf-resume and output path for resume image. The output images are stored in 'jpg' format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bffade2-11d4-42ee-bd17-d24ce4ec87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(pdf_path, img_path):\n",
    "      # Method for converting pdf resumes to jpg images. \n",
    "      images = convert_from_path(pdf_path)\n",
    "      # print(type(images))\n",
    "      for i in range(len(images)):\n",
    "        \n",
    "            # Save pages as images in the pdf\n",
    "          images[i].save(img_path + str(i) +'.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a3b50-9801-47d7-89c1-108bc0e3c9a5",
   "metadata": {},
   "source": [
    "This is the code to extract OpenAI key stored in `gpt_key.json` file. \\\n",
    "Format: \\\n",
    "    ```{ \n",
    "\t\"api_key\": \\<open_ai_key\\>\n",
    "    }```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35ffad11-5857-4851-bad4-e63cb22a1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_key.json', 'r') as file:\n",
    "      data = json.load(file)\n",
    "      api_key = data[\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459786a-75de-4155-b004-ac40c32c1b23",
   "metadata": {},
   "source": [
    "## Resume Parsing\n",
    "This is the code for converting the PDF resume to an image and parsing it using \"GPT-4o\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2858039-6d9f-4c40-b436-ec9e47dc1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Harish Sista', 'contact_info': {'phone': '(201) 310-5683', 'email': 'hsista@stevens.edu', 'address': '2642 28th St, Apt 4F, Astoria, NY-11102'}, 'summary': 'Ph.D. Candidate researching in ML and NLP with 7+ years of experience working with ML models, Big Data, and Cloud Computing platforms and 2+ years of experience working in a professional environment. Spearheaded an Evidence Extraction and Fact Verification model using Prompt Engineering and tested it with various LLMs. Invented a Black Box Optimization model for online hyperparameter fine-tuning, significantly enhancing model performance in real-time applications.', 'skills': {'programming_languages': ['Python', 'SQL', 'C++', 'Java', 'Swift', 'HTML'], 'ai_tools': ['PyTorch', 'HuggingFace', 'TensorFlow', 'AutoML', 'SciKitLearn', 'NumPy'], 'llms': ['GPT', 'LLAMA', 'BLOOM', 'BERT'], 'data_engineering': ['AWS EC2', 'FireWorks AI', 'Lightning AI', 'Data Pipelines', 'Data Augmentation'], 'cloud_platforms': ['AWS', 'Google Cloud', 'GIT', 'Heroku'], 'research_interests': ['NLP', 'Generative AI', 'AutoML', 'Data Science']}, 'education': [{'degree': 'Ph.D. in Machine Learning', 'institution': 'Stevens Institute of Technology', 'department': 'Computer Engineering', 'duration': '01/2018 – Present'}, {'degree': 'M.Eng. in Software Engineering', 'institution': 'Stevens Institute of Technology', 'department': 'Electrical Engineering', 'duration': '01/2014 – 12/2015'}, {'degree': 'B.Eng. in Electronics and Communication Engineering', 'institution': 'M.V.S.R Engineering College', 'location': 'Hyderabad, TG, India', 'duration': '08/2009 – 05/2013'}], 'research_experience': [{'position': 'Infinity Lab', 'institution': 'Stevens Institute of Technology', 'location': 'Hoboken, NJ', 'duration': '01/2018 – Present', 'responsibilities': ['Work with various LLMs to address the challenges of Fact Verification using Prompt Engineering, Text Generation, Classification and Evidence Extraction Tasks.', 'Built various Python Libraries using Multiprocessing to work efficiently with big datasets.', 'Surveyed and implemented various Attention Networks, DNNs and Generative Models to perform NLP tasks of Data Extraction, Modeling, Regression, Ranking, and Classification.', 'Collaborated in creating various Scientific, social media, and Misinformation Datasets.', 'Developed an AI based iOS application to perform MoCA test for early detection of Alzheimer’s.']}], 'work_experience': [{'position': 'Research Assistant', 'institution': 'Stevens Institute of Technology', 'location': 'Hoboken, NJ', 'duration': '10/2018 – 09/2019', 'responsibilities': ['Created a chemistry literature dataset for the purpose of similarity search with search queries.', 'Preprocessed the dataset, using PDF conversion tools and NLTK library to remove the noise.', 'Produced a Novel Generative Ranking Model using Topic Modeling and KeyPhrase analysis, to extract most relevant papers related to the search query.']}, {'position': 'AI Engineer/iOS Developer', 'institution': 'Fresh Digital Group', 'location': 'NY, NY', 'duration': '07/2016 – 06/2017', 'responsibilities': ['Collaborated with Content Writers and Creative Team to individually design and deploy 30 chat applications for Amazon-Alexa which won appreciation from tech newsletters.', 'Developed various iOS, iMessage and tvOS applications in conjunction with several teams.', 'Helped company obtain a preferred partnership with Amazon-Alexa and launching partnership with Microsoft-Cortana.']}], 'certifications': [{'title': 'Databases and SQL for Data Science with Python', 'issuer': 'IBM, Coursera', 'date': '09/09/2024'}, {'title': 'Foundations of Objective-C App Development', 'issuer': 'University of California, Irvine', 'date': '04/04/2016'}]}\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "get_img('Harish_Resume_PhD.pdf', './Harish_Resume')\n",
    "\n",
    "sys_prompt = \"You are a resume parser. Given the image of the resume, parse every section and provide the output in a JSON format.\"\n",
    "user_prompt=\"Can you parse all sections of this resume?\"\n",
    "\n",
    "image_worker = ImageWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=sys_prompt, user_prompt=user_prompt)\n",
    "parsed_resume = image_worker.get_output('Harish_Resume0.jpg')\n",
    "print(parsed_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7061118-f685-4836-8cd0-646c24949a76",
   "metadata": {},
   "source": [
    "## Add CV and additional information\n",
    "The current_cv instance keeps a record of the most recent updated Cover Letter and additional information on work experience, projects, achievements, and certifications. \n",
    "\n",
    "### Input arguments:\n",
    "`resume`=Parsed resume (Dict). \\\n",
    "`cv` = Cover letter text. \\\n",
    "`add_skills` = Additional skills not mentioned in the resume (Dict). \\\n",
    "`add_work_experience` = Additional work experience not mentioned in the resume (Dict). \\\n",
    "`add_education` = Additional education not mentioned in the resume (Dict). \\\n",
    "`add_projects` = Additional Projects not mentioned in the resume (Dict). \\\n",
    "`add_achievements` = Additional achievements not mentioned in the resume (Dict). \\\n",
    "`add_certifications` = Additional certifications not mentioned in the resume (Dict). \n",
    "\n",
    "#### additional_information format:\n",
    "```{``` \\\n",
    "```\"information\": text,``` \\\n",
    "```\"organization\": text,``` \\\n",
    "```\"date\": \"dd/mm/yyyy - dd/mm/yyyy\" (or) \"dd/mm/yyyy\"``` \\\n",
    "```}```\n",
    "\n",
    "The job_listing instance keeps a record of the requirements and description of the job posting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29a6c5a8-649f-4d08-b625-1a680a9ec18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'contact_info', 'summary', 'skills', 'education', 'research_experience', 'work_experience', 'certifications'])\n"
     ]
    }
   ],
   "source": [
    "print(parsed_resume.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1962296-a716-41bb-9b5a-480f16577eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"current_resume\": {\n",
      "    \"name\": \"Harish Sista\",\n",
      "    \"contact_info\": {\n",
      "      \"phone\": \"(201) 310-5683\",\n",
      "      \"email\": \"hsista@stevens.edu\",\n",
      "      \"address\": \"2642 28th St, Apt 4F, Astoria, NY-11102\"\n",
      "    },\n",
      "    \"summary\": \"Ph.D. Candidate researching in ML and NLP with 7+ years of experience working with ML models, Big Data, and Cloud Computing platforms and 2+ years of experience working in a professional environment. Spearheaded an Evidence Extraction and Fact Verification model using Prompt Engineering and tested it with various LLMs. Invented a Black Box Optimization model for online hyperparameter fine-tuning, significantly enhancing model performance in real-time applications.\",\n",
      "    \"skills\": {\n",
      "      \"programming_languages\": [\"Python\", \"SQL\", \"C++\", \"Java\", \"Swift\", \"HTML\"],\n",
      "      \"ai_tools\": [\"PyTorch\", \"HuggingFace\", \"TensorFlow\", \"AutoML\", \"SciKitLearn\", \"NumPy\"],\n",
      "      \"llms\": [\"GPT\", \"LLAMA\", \"BLOOM\", \"BERT\"],\n",
      "      \"data_engineering\": [\"AWS EC2\", \"FireWorks AI\", \"Lightning AI\", \"Data Pipelines\", \"Data Augmentation\"],\n",
      "      \"cloud_platforms\": [\"AWS\", \"Google Cloud\", \"GIT\", \"Heroku\"],\n",
      "      \"research_interests\": [\"NLP\", \"Generative AI\", \"AutoML\", \"Data Science\"]\n",
      "    },\n",
      "    \"education\": [\n",
      "      {\n",
      "        \"degree\": \"Ph.D. in Machine Learning\",\n",
      "        \"institution\": \"Stevens Institute of Technology\",\n",
      "        \"department\": \"Computer Engineering\",\n",
      "        \"duration\": \"01/2018 – Present\"\n",
      "      },\n",
      "      {\n",
      "        \"degree\": \"M.Eng. in Software Engineering\",\n",
      "        \"institution\": \"Stevens Institute of Technology\",\n",
      "        \"department\": \"Electrical Engineering\",\n",
      "        \"duration\": \"01/2014 – 12/2015\"\n",
      "      },\n",
      "      {\n",
      "        \"degree\": \"B.Eng. in Electronics and Communication Engineering\",\n",
      "        \"institution\": \"M.V.S.R Engineering College\",\n",
      "        \"location\": \"Hyderabad, TG, India\",\n",
      "        \"duration\": \"08/2009 – 05/2013\"\n",
      "      }\n",
      "    ],\n",
      "    \"research_experience\": [\n",
      "      {\n",
      "        \"position\": \"Infinity Lab\",\n",
      "        \"institution\": \"Stevens Institute of Technology\",\n",
      "        \"location\": \"Hoboken, NJ\",\n",
      "        \"duration\": \"01/2018 – Present\",\n",
      "        \"responsibilities\": [\n",
      "          \"Work with various LLMs to address the challenges of Fact Verification using Prompt Engineering, Text Generation, Classification and Evidence Extraction Tasks.\",\n",
      "          \"Built various Python Libraries using Multiprocessing to work efficiently with big datasets.\",\n",
      "          \"Surveyed and implemented various Attention Networks, DNNs and Generative Models to perform NLP tasks of Data Extraction, Modeling, Regression, Ranking, and Classification.\",\n",
      "          \"Collaborated in creating various Scientific, social media, and Misinformation Datasets.\",\n",
      "          \"Developed an AI based iOS application to perform MoCA test for early detection of Alzheimer’s.\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"work_experience\": [\n",
      "      {\n",
      "        \"position\": \"Research Assistant\",\n",
      "        \"institution\": \"Stevens Institute of Technology\",\n",
      "        \"location\": \"Hoboken, NJ\",\n",
      "        \"duration\": \"10/2018 – 09/2019\",\n",
      "        \"responsibilities\": [\n",
      "          \"Created a chemistry literature dataset for the purpose of similarity search with search queries.\",\n",
      "          \"Preprocessed the dataset, using PDF conversion tools and NLTK library to remove the noise.\",\n",
      "          \"Produced a Novel Generative Ranking Model using Topic Modeling and KeyPhrase analysis, to extract most relevant papers related to the search query.\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"position\": \"AI Engineer/iOS Developer\",\n",
      "        \"institution\": \"Fresh Digital Group\",\n",
      "        \"location\": \"NY, NY\",\n",
      "        \"duration\": \"07/2016 – 06/2017\",\n",
      "        \"responsibilities\": [\n",
      "          \"Collaborated with Content Writers and Creative Team to individually design and deploy 30 chat applications for Amazon-Alexa which won appreciation from tech newsletters.\",\n",
      "          \"Developed various iOS, iMessage and tvOS applications in conjunction with several teams.\",\n",
      "          \"Helped company obtain a preferred partnership with Amazon-Alexa and launching partnership with Microsoft-Cortana.\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"certifications\": [\n",
      "      {\n",
      "        \"title\": \"Databases and SQL for Data Science with Python\",\n",
      "        \"issuer\": \"IBM, Coursera\",\n",
      "        \"date\": \"09/09/2024\"\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"Foundations of Objective-C App Development\",\n",
      "        \"issuer\": \"University of California, Irvine\",\n",
      "        \"date\": \"04/04/2016\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"job_description\": {\n",
      "    \"company_description\": \"It all started in sunny San Diego, California in 2004 when a visionary engineer, Fred Luddy, saw the potential to transform how we work. Fast forward to today — ServiceNow stands as a global market leader, bringing innovative AI-enhanced technology to over 8,100 customers, including 85% of the Fortune 500®. Our intelligent cloud-based platform seamlessly connects people, systems, and processes to empower organizations to find smarter, faster, and better ways to work.\",\n",
      "    \"job_description\": \"We’re not yesterday’s IT department, we're Digital Technology. The world around us keeps changing and so do we. We’re redefining what it means to be IT with a mindset centered on transformation, experience, AI-driven automation, innovation, and growth. Ultimately, we strive to make the world work better for our employees and customers.\",\n",
      "    \"responsibilities\": [\n",
      "      \"Research and experiment with the latest advancements in AI, AutoML, and Generative AI.\",\n",
      "      \"Collaborate with data scientists and build high-quality datasets for rapid development of ML and GenAI POCs.\",\n",
      "      \"Build efficient data pipelines for preparing and delivering datasets that enable quick iterations.\",\n",
      "      \"Quickly assemble ML/GenAI datasets, prototype AI solutions, and deliver POCs through tools like Gradio and Streamlit.\",\n",
      "      \"Explore tools and methods for automated feature engineering techniques.\",\n",
      "      \"Collaborate with cross-functional teams to develop innovative AI-driven solutions.\"\n",
      "    ],\n",
      "    \"qualifications\": {\n",
      "      \"education\": \"Bachelor’s or Master’s degree in Computer Science, Data Engineering, Machine Learning, or a related field. PhD is a plus.\",\n",
      "      \"experience\": \"1-3 years of experience working on machine learning or AI projects, with a focus on model feature set preparation.\",\n",
      "      \"skills\": [\n",
      "        \"Strong experience with SQL and Python programming, with a focus on data engineering.\",\n",
      "        \"Proven experience quickly building data pipelines and automating data workflows.\",\n",
      "        \"Familiarity with AutoML tools and automated feature engineering techniques.\"\n",
      "      ],\n",
      "      \"extra_consideration\": [\n",
      "        \"Experience using AI tools in Snowflake.\",\n",
      "        \"Experience in quickly developing GenAI prompts.\",\n",
      "        \"Creation of interactive demos and/or model simulators.\"\n",
      "      ]\n",
      "    }\n",
      " \n"
     ]
    }
   ],
   "source": [
    "record = Record(resume=parsed_resume)\n",
    "with open('job_description.txt', 'r') as f:\n",
    "    job_description = f.read()\n",
    "\n",
    "ro_system_prompt = 'You are a resume optimizer. \\\n",
    "Given the current resume(#current_resume) and the job description(#job_description), \\\n",
    "rewrite the current resume to highlight the relevant skills, experience, and quantifiable achievements that match the job description.'\n",
    "\n",
    "ro_user_prompt = f'Please optimize my current resume \\\n",
    "The current resume is provided under #current_resume \\\n",
    "and job description is provided under #job_description \\\n",
    "\\n\\t#current_resume: {record.resume} \\\n",
    "\\n\\t#job_description: {job_description}'\n",
    "\n",
    "ro_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=ro_sys_prompt, user_prompt=ro_user_prompt)\n",
    "new_resume = ro_text_worker.get_output()\n",
    "print(new_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "facf2e0e-418a-4fce-952c-dfba798e19cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'keywords': [{'keyword': 'AI & GenAI experience', 'question': 'The job description requires 1-3 years of experience working on machine learning or AI projects with a focus on model feature set preparation. How does your experience align with this requirement?'}, {'keyword': 'Data Engineering Expertise', 'question': 'The role demands proven experience in quickly building data pipelines and using large datasets for ML/GenAI applications. Can you elaborate on your specific experience in data engineering, particularly with platforms like Snowflake?'}, {'keyword': 'AutoML familiarity', 'question': 'The position favors familiarity with AutoML tools and automated feature engineering techniques. Can you clarify your exposure to AutoML concepts and tools in your previous work?'}, {'keyword': 'AI in Snowflake', 'question': 'The job mentions that experience using AI tools in Snowflake is a plus. Can you detail any experience you have with Snowflake or similar tools in relation to AI?'}, {'keyword': 'GenAI Prompt Engineering', 'question': 'The role highlights the importance of experience in quickly developing GenAI prompts and understanding hallucination risks. How have you approached prompt engineering in your previous projects?'}, {'keyword': 'Interactive Demos', 'question': 'The qualifications include creation of interactive demos and model simulators. Can you share any experience you have in developing interactive demonstrations or models that showcase functionality and user experience?'}]}\n"
     ]
    }
   ],
   "source": [
    "ra_system_prompt = 'You are a resume analyzer and a question generator.\\\n",
    "                    given the current resume(#current_resume) and the job description(#job_description), \\\n",
    "                    provide keywords from the job description where the resume fails to address the requirements. \\\n",
    "                    Provide the keywords with a question describing how the resume fails to meet this requirement. \\\n",
    "                    Present the output in the following JSON output format: \\\n",
    "                    \\n\\t{\\\"keywords\\\": [{\"keyword\": system keyword, \"question\": system keyword question}]}'\n",
    "ra_user_prompt = f'#current_resume: {record.resume} \\\n",
    "                    #job_description: {job_description}'\n",
    "\n",
    "ra_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=ra_system_prompt, user_prompt=ra_user_prompt, json_format=True)\n",
    "system_insights = ra_text_worker.get_output()\n",
    "print(system_insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a43e7-b651-4640-8631-d8a2c28d6f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.10] *",
   "language": "python",
   "name": "conda-env-py3.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
