{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b09256-8097-4588-938f-37a2f16507c4",
   "metadata": {},
   "source": [
    "# Workbench for ResumeAssistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79634a30-eea3-403d-935a-a66ce9bd5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "# ImageWorker takes in the path to jpg resume image and returns the contents of the resume in a json format. \n",
    "from resumeassistant.operator.worker import ImageWorker, TextWorker\n",
    "from resumeassistant.data.candidate_record import Record, QA_Knowledge\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad03abd-9b24-4e84-924b-07b7bd8f27ff",
   "metadata": {},
   "source": [
    "# PDF to jpg image converter function\n",
    "This function takes the input path for pdf-resume and output path for resume image. The output images are stored in 'jpg' format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bffade2-11d4-42ee-bd17-d24ce4ec87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(pdf_path, img_path):\n",
    "      # Method for converting pdf resumes to jpg images. \n",
    "      images = convert_from_path(pdf_path)\n",
    "      # print(type(images))\n",
    "      for i in range(len(images)):\n",
    "        \n",
    "            # Save pages as images in the pdf\n",
    "          images[i].save(img_path + str(i) +'.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a3b50-9801-47d7-89c1-108bc0e3c9a5",
   "metadata": {},
   "source": [
    "This is the code to extract OpenAI key stored in `gpt_key.json` file. \\\n",
    "Format: \\\n",
    "    ```{ \n",
    "\t\"api_key\": \\<open_ai_key\\>\n",
    "    }```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ffad11-5857-4851-bad4-e63cb22a1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_key.json', 'r') as file:\n",
    "      data = json.load(file)\n",
    "      api_key = data[\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459786a-75de-4155-b004-ac40c32c1b23",
   "metadata": {},
   "source": [
    "## Resume Parsing\n",
    "This is the code for converting the PDF resume to an image and parsing it using \"GPT-4o\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2858039-6d9f-4c40-b436-ec9e47dc1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Harish Sista', 'contact': {'phone': '(201) 310-5683', 'email': 'hsista@stevens.edu', 'address': '2642 28th St, Apt 4F, Astoria, NY-11102'}, 'summary': 'Ph.D. Candidate researching in ML and NLP with 7+ years of experience working with ML models, Big Data, and Cloud Computing platforms and 2+ years of experience working in a professional environment. Spearheaded an Evidence Extraction and Fact Verification model using Prompt Engineering and tested it with various LLMs. Invented a Black Box Optimization model for online hyperparameter fine-tuning, significantly enhancing model performance in real-time applications.', 'skills': {'programming_languages': ['Python', 'SQL', 'NoSQL', 'C++', 'Java', 'HTML'], 'ai_tools': ['PyTorch', 'HuggingFace', 'TensorFlow', 'AutoML', 'SciKitLearn', 'NumPy'], 'llms': ['GPT', 'LLaMA', 'BLOOM', 'BERT'], 'data_engineering': ['AWS EC2', 'FireWorks AI', 'Lightning AI', 'Data Pipelines', 'Data Augmentation'], 'cloud_platforms': ['AWS', 'Google Cloud', 'GIT', 'Heroku'], 'research_interests': ['NLP', 'Generative AI', 'Data Science']}, 'education': [{'degree': 'Ph.D. in Machine Learning', 'institution': 'Stevens Institute of Technology', 'location': 'Hoboken', 'dates': '01/2018 – Present'}, {'degree': 'M.Eng. in Software Engineering', 'institution': 'Stevens Institute of Technology', 'location': 'Hoboken', 'dates': '01/2014 – 12/2015'}, {'degree': 'B.Eng. in Electronics and Communication Engineering', 'institution': 'M.V.S.R Engineering College', 'location': 'Hyderabad, TG, India', 'dates': '08/2009 – 05/2013'}], 'research_experience': {'position': 'Infinity Lab', 'institution': 'Stevens Institute of Technology', 'location': 'Hoboken, NJ', 'dates': '01/2018 – Present', 'responsibilities': ['Work with various LLMs to address the challenges of Fact Verification using Prompt Engineering, Text Generation, Classification and Evidence Extraction Tasks.', 'Built various Python Libraries using Multiprocessing to work efficiently with big datasets.', 'Surveyed and implemented various Attention Networks, DNNs and Generative Models to perform NLP tasks of Data Extraction, Modeling, Regression, Ranking, and Classification.', 'Collaborated in creating various Scientific, social media, and Misinformation Datasets.', 'Developed an AI based iOS application to perform MoCA test for early detection of Alzheimers.', 'Organized and maintained hardware and software for the department Lab-Server and built a personal Machine Learning RIG.']}, 'work_experience': [{'position': 'Research Assistant', 'institution': 'Stevens Institute of Technology', 'location': 'Hoboken, NJ', 'dates': '10/2018 – 09/2019', 'responsibilities': ['Created a chemistry literature dataset for the purpose of similarity search with search queries.', 'Preprocessed the dataset, using PDF conversion tools and NLTK library to remove the noise.', 'Produced a Novel Generative Ranking Model using Topic Modeling and KeyPhrase analysis, to extract most relevant papers related to the search query.']}, {'position': 'AI Engineer/iOS Developer', 'institution': 'Fresh Digital Group', 'location': 'NY, NY', 'dates': '07/2016 – 06/2017', 'responsibilities': ['Collaborated with Content Writers and Creative Team to individually design and deploy 30 chat applications for Amazon-Alexa which won appreciation from tech newsletters.', 'Developed various iOS, iMessage and tvOS applications in conjunction with several teams.', 'Helped company obtain a preferred partnership with Amazon-Alexa and launching partnership with Microsoft-Cortana.']}], 'certifications': [{'name': 'Databases and SQL for Data Science with Python', 'provider': 'IBM, Coursera', 'date': '09/09/2024'}, {'name': 'Foundations of Objective-C App Development', 'provider': 'University of California, Irvine', 'date': '04/04/2016'}]}\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "get_img('Resume_PhD.pdf', './Harish_Resume')\n",
    "\n",
    "sys_prompt = \"You are a resume parser. Given the image of the resume, parse every section and provide the output in a JSON format.\"\n",
    "user_prompt=\"Can you parse all sections of this resume?\"\n",
    "\n",
    "image_worker = ImageWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=sys_prompt, user_prompt=user_prompt)\n",
    "parsed_resume = image_worker.get_output('Harish_Resume0.jpg')\n",
    "print(parsed_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7061118-f685-4836-8cd0-646c24949a76",
   "metadata": {},
   "source": [
    "## Add CV and additional information\n",
    "The current_cv instance keeps a record of the most recent updated Cover Letter and additional information on work experience, projects, achievements, and certifications. \n",
    "\n",
    "### Input arguments:\n",
    "`resume`=Parsed resume (Dict). \\\n",
    "`cv` = Cover letter text. \\\n",
    "`add_skills` = Additional skills not mentioned in the resume (Dict). \\\n",
    "`add_work_experience` = Additional work experience not mentioned in the resume (Dict). \\\n",
    "`add_education` = Additional education not mentioned in the resume (Dict). \\\n",
    "`add_projects` = Additional Projects not mentioned in the resume (Dict). \\\n",
    "`add_achievements` = Additional achievements not mentioned in the resume (Dict). \\\n",
    "`add_certifications` = Additional certifications not mentioned in the resume (Dict). \n",
    "\n",
    "#### additional_information format:\n",
    "```{``` \\\n",
    "```\"information\": text,``` \\\n",
    "```\"organization\": text,``` \\\n",
    "```\"date\": \"dd/mm/yyyy - dd/mm/yyyy\" (or) \"dd/mm/yyyy\"``` \\\n",
    "```}```\n",
    "\n",
    "The job_listing instance keeps a record of the requirements and description of the job posting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a6c5a8-649f-4d08-b625-1a680a9ec18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'contact', 'summary', 'skills', 'education', 'research_experience', 'work_experience', 'certifications'])\n"
     ]
    }
   ],
   "source": [
    "print(parsed_resume.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf707847-93a0-406f-ba52-764d1e63b86c",
   "metadata": {},
   "source": [
    "## Resume Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1962296-a716-41bb-9b5a-480f16577eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_resume(candidate_info, job_description):\n",
    "    ro_system_prompt = 'You are a resume optimizer. \\\n",
    "    Given the candidate information(#candidate_info) and the job description(#job_description), \\\n",
    "    rewrite the current resume to highlight the relevant skills, experience, and quantifiable achievements that match the job description. \\\n",
    "    Provide the output in a JSON format.'\n",
    "    \n",
    "    ro_user_prompt = f'#candidate_info: {candidate_info} \\\n",
    "                    \\n#job_description: {job_description}'\n",
    "    \n",
    "    ro_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=ro_system_prompt, user_prompt=ro_user_prompt, json_format=True)\n",
    "    new_resume = ro_text_worker.get_output()\n",
    "    return new_resume\n",
    "# print(new_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a0b0d-b45b-4490-beb0-6627f5947dfc",
   "metadata": {},
   "source": [
    "## Resume Screening\n",
    "In this section, the generated resume is screened based on how informative it is w.r.t the job posting. \n",
    "The resume screener gathers the keywords from the job description where the new resume fails to address, and a question requesting the missing information to address the unfulfilled requirements. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facf2e0e-418a-4fce-952c-dfba798e19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_resume_CL(resume, cover_leter, job_description):\n",
    "    ra_system_prompt = 'You are a resume screener and a question generator.\\\n",
    "                        given the current resume(#current_resume) and the cover letter(#current_cover_letter) and the job description(#job_description), \\\n",
    "                        provide keywords from the job description where the resume fails to address the requirements. \\\n",
    "                        Provide the keywords with a question describing how the resume fails to meet this requirement. \\\n",
    "                        Present the output in the following JSON output format: \\\n",
    "                        \\n\\t{\\\"keywords\\\": [{\"keyword\": system keyword, \"question\": system keyword question}]}'\n",
    "    # ra_user_prompt = f'#current_resume: {record.resume} \\\n",
    "                        #job_description: {job_description}'\n",
    "    \n",
    "    ra_user_prompt = f'#current_resume: {resume} \\\n",
    "                        #job_description: {job_description} \\\n",
    "                        #current_cover_letter: {cover_leter}' \n",
    "    \n",
    "    ra_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=ra_system_prompt, user_prompt=ra_user_prompt, json_format=True)\n",
    "    system_insights = ra_text_worker.get_output()\n",
    "    return system_insights\n",
    "# print(system_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357537e-0068-4c44-841c-e0436280de95",
   "metadata": {},
   "source": [
    "## Cover Letter Generation\n",
    "This is the code for generating the cover letter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c58ec11-f753-4edd-a5be-103b6de966bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CL_generator(candidate_info, job_description):\n",
    "\n",
    "    cl_system_prompt = \"You are a cover letter generator, given the candidate information(#candidate_info) and job description(#job_description). \\\n",
    "                        Generate a cover letter relevant to the job description highlighting the candidate's skills and achievements\"\n",
    "    \n",
    "    cl_user_prompt = f'#candidate_info: {candidate_info} \\\n",
    "                        #job_description: {job_description}'\n",
    "    \n",
    "    \n",
    "    cl_text_worker = TextWorker(client=client, model_id=\"gpt-4o-mini\", sys_prompt=cl_system_prompt, user_prompt=cl_user_prompt)\n",
    "    new_cl = cl_text_worker.get_output()\n",
    "    return new_cl\n",
    "# print(new_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305747b4-3a20-425e-885f-8066cf8aacb9",
   "metadata": {},
   "source": [
    "## Add additional knowledge from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1eb67d-fd26-48b8-9567-a0bb73cacd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cl = \"Hello Hiring Team, \\nI am pursuing my Ph.D. in the Computer Engineering department at Stevens Institute of Technology; \\\n",
    "            my research is focused on Natural Language Processing. \\\n",
    "            I work on applications related to the areas of Misinformation Research and Investigative Journalism using Evidence Extraction, \\\n",
    "            Fact Verification and Key-Phrase analysis; I research and work with Generative Models, Deep Learning models, Attention Networks, \\\n",
    "            and Large Language Models for Extraction and Verification Tasks. \\\n",
    "            My Dissertation Project is based on Fact-Verification and Evidence-Extraction using an Explainable Prompt-Engineering Model \\\n",
    "            I proposed. \\nEven though I chose the use cases of NLP as the focus of my research, \\\n",
    "            my work is more comprehensive than NLP-based models; \\\n",
    "            I have also created a low-cost Derivative-Free Optimization Method for parameter optimization in ML; \\\n",
    "            I am working on obtaining a Provisional Patent for this research. \\\n",
    "            I am immensely passionate about learning and analyzing the underlying Mathematical Concepts of Machine Learning Models; \\\n",
    "            I like educating myself on all the specifics of any problem statement, following the motivation of the research, \\\n",
    "            chronological evolution of the Problem-Solution framework, and feature analysis from historical to the SOTA models. \\\n",
    "            \\nI am currently seeking a job opportunity to hone my skills and work with a proficient team for an inspirational \\\n",
    "            cause where AI can be efficacious. \\nRegards, \\nHarish Sista, Ph.D. candidate, \\nComputer Engineering Department, \\\n",
    "            \\nStevens Institute of Technology.\"\n",
    "\n",
    "record = Record(resume=parsed_resume, cl=old_cl)\n",
    "# with open('job_description.txt', 'r') as f:\n",
    "#     job_description = f.read()\n",
    "\n",
    "job_description = \"We are seeking a talented AI/ML Developer to join our innovative team. \\\n",
    "            The ideal candidate will have strong expertise in machine learning algorithms, \\\n",
    "            data preprocessing, model development, fine-tuning large language models (LLMs), \\\n",
    "            and working with big data. You will work on creating, deploying, \\\n",
    "            and optimizing AI models to solve real-world problems and enhance our products.\\n \\\n",
    "            \\nResponsibilities: \\\n",
    "            \\n\\nDesign and develop machine learning models. \\\n",
    "            \\n\\nPreprocess and analyze large datasets. \\\n",
    "            \\nImplement and optimize algorithms for performance and scalability. \\\n",
    "            \\nFine-tune large language models (LLMs) for specific applications. \\\n",
    "            \\nManage and analyze big data to derive insights and improve models. \\\n",
    "            \\nCollaborate with cross-functional teams to integrate AI solutions. \\\n",
    "            \\nStay up-to-date with the latest advancements in AI and ML technologies. \\\n",
    "            \\n\\nRequirements: \\\n",
    "            \\n5+ years of experience in working with AI/LLMs. \\\n",
    "            \\nBachelor\\'s or Master\\'s degree in Computer Science, Data Science, or a related field. \\\n",
    "            \\nProficiency in Python and ML frameworks such as TensorFlow, PyTorch, or scikit-learn. \\\n",
    "            \\nExperience with data preprocessing and feature engineering. \\\n",
    "            \\nStrong understanding of machine learning algorithms and techniques. \\\n",
    "            \\nProven experience in fine-tuning large language models. \\\n",
    "            \\nExperience with big data tools and technologies (e.g., Hadoop, Spark). \\\n",
    "            \\nExcellent problem-solving and analytical skills. \\\n",
    "            \\nWhat we offer: \\\n",
    "            \\n\\nCompetitive salary that reflects your skills, experience, and contributions to the company. \\\n",
    "            \\nFlexible working hours and remote work options to support your personal and professional life. \\\n",
    "            \\nFull reimbursement for business-related travel expenses for group meet-ups. \\\n",
    "            \\nIndividual benefits and bonuses. \\\n",
    "            \\nJoin us to work on cutting-edge AI projects and make a significant impact in a dynamic and collaborative environment!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a85585c-1a2c-4280-91c5-3e36f6936c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'keywords': [{'keyword': '5+ years of experience in working with AI/LLMs', 'question': 'How does your resume demonstrate 5+ years of experience specifically working with AI/LLMs, as required by the job description?'}, {'keyword': 'Experience with big data tools and technologies (e.g., Hadoop, Spark)', 'question': 'Can you elaborate on any experience you have with big data tools and technologies such as Hadoop or Spark, which is mentioned in the job description but not addressed in your resume?'}, {'keyword': 'Experience with data preprocessing and feature engineering', 'question': 'How does your resume showcase your experience with data preprocessing and feature engineering, which is a key requirement in the job description?'}, {'keyword': 'Excellent problem-solving and analytical skills', 'question': 'What examples can you provide from your resume that highlight your problem-solving and analytical skills, as emphasized in the job description?'}, {'keyword': 'Strong understanding of machine learning algorithms and techniques', 'question': 'Could you clarify how your resume reflects a strong understanding of various machine learning algorithms and techniques, a crucial requirement outlined in the job description?'}]}\n"
     ]
    }
   ],
   "source": [
    "key_questions = screen_resume_CL(record.resume, record.cl, job_description)\n",
    "print(key_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e4096-62f2-45fd-ab2e-4b417975abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "key_knowledge = [{'5+ years of experience in working with AI/LLMs': { \n",
    "                  'question': 'How does your resume demonstrate 5+ years of experience specifically working with AI/LLMs, \\\n",
    "                  as required by the job description?'}}, \n",
    "                 {'Experience with big data tools and technologies (e.g., Hadoop, Spark)':{ \n",
    "                'question': 'Can you elaborate on any experience you have with big data tools and technologies such as Hadoop or Spark, \\\n",
    "                which is mentioned in the job description but not addressed in your resume?'}}, \n",
    "                 {'Experience with data preprocessing and feature engineering': { \n",
    "                  'question': 'How does your resume showcase your experience with data preprocessing and feature engineering, \\\n",
    "                  which is a key requirement in the job description?'}}, \n",
    "                 {'Excellent problem-solving and analytical skills':{\n",
    "                  'question': 'What examples can you provide from your resume that highlight your problem-solving and analytical skills, \\\n",
    "                  as emphasized in the job description?'}}, \n",
    "                 {'Strong understanding of machine learning algorithms and techniques': { \n",
    "                  'question': 'Could you clarify how your resume reflects a strong understanding of various machine learning algorithms \\\n",
    "                  and techniques, a crucial requirement outlined in the job description?'}}]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.10] *",
   "language": "python",
   "name": "conda-env-py3.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
